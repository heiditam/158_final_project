{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages\n",
    "import gzip\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)\n",
    "import pandas as pd\n",
    "import json\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(path):\n",
    "  g = gzip.open(path, 'r')\n",
    "  for l in g:\n",
    "    yield json.loads(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "review_filepath = \"../assignment2/review-Idaho.json.gz\"\n",
    "meta_filepath = \"../assignment2/meta-Idaho.json.gz\"\n",
    "\n",
    "reviews = []\n",
    "bizs = []\n",
    "for l in parse(review_filepath):\n",
    "    reviews.append(l)\n",
    "\n",
    "for l in parse(meta_filepath):\n",
    "    bizs.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "729928\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "700132"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_w_plus_minus_responses = [review for review in reviews if review.get(\"resp\")]\n",
    "print(len(reviews_w_plus_minus_responses))\n",
    "reviews_with_responses = [review for review in reviews \n",
    "                          if ((review.get(\"resp\")) and (review['resp']['time'] - review['time'] > 0))]\n",
    "len(reviews_with_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new resp_time variable within each review\n",
    "for r in reviews_with_responses:\n",
    "    r['resp_time'] = r['resp']['time'] - r['time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_id': '115114032166130224762',\n",
       " 'name': 'Mariah Schaeffer',\n",
       " 'time': 1589989743506,\n",
       " 'rating': 5,\n",
       " 'text': 'Kevin and Shannon are amazing! They were very sweet and made the job fast! Also they are one of the cheeper junk removal services! I will for sure use again!',\n",
       " 'pics': None,\n",
       " 'resp': {'time': 1591139557205,\n",
       "  'text': 'Thank you for hiring us for your junk removal!'},\n",
       " 'gmap_id': '0x54afb4c19c4bffff:0x9389114191ca2781',\n",
       " 'resp_time': 1149813699}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_with_responses[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model #1 Baseline - Review Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_feat(d):\n",
    "    feat = [1]\n",
    "    try:\n",
    "        text_length = len(d['text'])\n",
    "    except (KeyError, TypeError):\n",
    "        text_length = 0 \n",
    "    feat.append(text_length)\n",
    "    feat.append(d.get('rating', 0))\n",
    "    feat.append(d.get('time', 0))\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarizeWeekResponse(y):\n",
    "    if y/1000/60/60/24 <= 7: #response within 5 days\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle_data = reviews_with_responses.copy()\n",
    "# print(shuffle_data[0])\n",
    "# random.shuffle(shuffle_data)\n",
    "# print(shuffle_data[0])\n",
    "\n",
    "# start = time.time()\n",
    "# encodedDataXBase = [baseline_feat(r) for r in shuffle_data]\n",
    "# encodedDatayBase = [r['resp_time'] for r in shuffle_data]\n",
    "# end = time.time()\n",
    "# print(f\"encoding time = {end-start}s\")\n",
    "\n",
    "# # split_spot = int(len(encodedDataXBase)*0.8)\n",
    "# # XTrainBase = encodedDataXBase[:split_spot]\n",
    "# # yTrainBase = encodedDatayBase[:split_spot]\n",
    "# # XTestBase = encodedDataXBase[split_spot:]\n",
    "# # yTestBase = encodedDatayBase[split_spot:]\n",
    "\n",
    "scalerBase = StandardScaler()\n",
    "\n",
    "XTrainBase = encodedDataXBase[:split_spot]\n",
    "XTrainBase_scaled = scalerBase.fit_transform(XTrainBase)\n",
    "\n",
    "yTrainBase = np.array(list(map(binarizeWeekResponse, np.array(encodedDatayBase[:split_spot]))))\n",
    "\n",
    "XTestBase = encodedDataXBase[split_spot:]\n",
    "XTestBase_scaled = scalerBase.transform(XTestBase)\n",
    "\n",
    "yTestBase = np.array(list(map(binarizeWeekResponse, np.array(encodedDatayBase[split_spot:]))))\n",
    "\n",
    "#X = [baseline_feat(r) for r in reviews_with_responses]\n",
    "#y = [r['resp_time'] for r in reviews_with_responses]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.         -0.06958226 -0.10118254  0.25875767]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5598277475058382"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# modelBase = sklearn.linear_model.LinearRegression(fit_intercept=False)\n",
    "# modelBase.fit(XTrainBase, yTrainBase)\n",
    "\n",
    "modelBase = sklearn.linear_model.LogisticRegression(class_weight = \"balanced\")\n",
    "modelBase.fit(XTrainBase_scaled, yTrainBase)\n",
    "print(modelBase.coef_)\n",
    "y_predBase = modelBase.predict(XTestBase_scaled)\n",
    "acc = np.mean(yTestBase == y_predBase)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist([np.sqrt(x**2)/ 1000 / 60 / 60 / 24 for x in (yTestBase - y_pred_base)], bins = 30)\n",
    "# plt.title('error in days')\n",
    "# plt.show() ### shows outlier around 8 years. Is this the true y value causing it? sort and find top difference later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Model - Business Features included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "bizByID = defaultdict(dict)\n",
    "for b in bizs:\n",
    "    bizByID[b['gmap_id']] = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat(r):\n",
    "    feat = [1]\n",
    "    try:\n",
    "        text_length = len(r['text'])\n",
    "    except (KeyError, TypeError):\n",
    "        text_length = 0 \n",
    "    feat.append(text_length)\n",
    "    feat.append(r.get('rating', 0))\n",
    "    feat.append(r.get('time', 0))\n",
    "\n",
    "    ### Using biz\n",
    "    gmap_id = r.get('gmap_id')\n",
    "    #if id from review in biz IDs, get the avg review from the biz\n",
    "    if gmap_id in bizByID.keys() and isinstance(bizByID[gmap_id], dict):\n",
    "        avg_rating = bizByID[gmap_id].get('avg_rating', 0)\n",
    "    else:\n",
    "        avg_rating = 0  # Default if gmap_id is invalid or not in b\n",
    "    feat.append(avg_rating)\n",
    "\n",
    "    # relative bizs\n",
    "    try:\n",
    "        num_simlr_biz = len(bizByID[gmap_id].get('relative_results', 0))\n",
    "    except Exception as e:\n",
    "        num_simlr_biz = 0\n",
    "    feat.append(num_simlr_biz)\n",
    "    \n",
    "    # state\n",
    "    try:\n",
    "        state_cat = bizByID[gmap_id].get('state').split()[0]\n",
    "        if state_cat == 'Open':\n",
    "            state_ohe=[0,0,0,0,0,0,1]\n",
    "        elif state_cat == 'Opens':\n",
    "            state_ohe=[0,0,0,0,0,1,0]\n",
    "        elif state_cat == 'Closed':\n",
    "            state_ohe=[0,0,0,0,1,0,0]\n",
    "        elif state_cat == 'Closes':\n",
    "            state_ohe=[0,0,0,1,0,0,0]\n",
    "        elif state_cat == 'Permanently':\n",
    "            state_ohe=[0,0,1,0,0,0,0]\n",
    "        elif state_cat == 'Temporarily':\n",
    "            state_ohe=[0,1,0,0,0,0,0]\n",
    "        else:\n",
    "            print(state_cat)\n",
    "    except Exception as e:\n",
    "        state_ohe=[1,0,0,0,0,0,0]\n",
    "    feat += state_ohe\n",
    "\n",
    "    #Time of year\n",
    "    feat.append(r.get('time', 0) % (1000 * 60 * 60 * 24 * 365))\n",
    "    \n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarizeWeekResponse(y):\n",
    "    if y/1000/60/60/24 <= 7: #response within 7 days\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoding time = 168.7272891998291s\n"
     ]
    }
   ],
   "source": [
    "# shuffle_data = reviews_with_responses.copy() # DEFINED ABOVE\n",
    "# print(shuffle_data[0])\n",
    "# random.shuffle(shuffle_data)\n",
    "# print(shuffle_data[0])\n",
    "\n",
    "start = time.time()\n",
    "encodedDataX = [feat(r) for r in shuffle_data]\n",
    "encodedDatay = [r['resp_time'] for r in shuffle_data]\n",
    "end = time.time()\n",
    "print(f\"encoding time = {end-start}s\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "split_spot = int(len(encodedDataX)*0.8)\n",
    "\n",
    "XTrain = encodedDataX[:split_spot]\n",
    "XTrain_scaled = scaler.fit_transform(XTrain)\n",
    "\n",
    "yTrain = np.array(list(map(binarizeWeekResponse, np.array(encodedDatay[:split_spot]))))\n",
    "\n",
    "XTest = encodedDataX[split_spot:]\n",
    "XTest_scaled = scaler.transform(XTest)\n",
    "\n",
    "yTest = np.array(list(map(binarizeWeekResponse, np.array(encodedDatay[split_spot:]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.         -0.5969107  -2.10996881 -1.24347625 -1.74979085  0.47689901\n",
      "  1.57421629 -0.05447157 -0.10293115 -0.1516527  -0.85150535 -0.10564278\n",
      " -0.56999082 -1.37702213] 0\n",
      "0.739450248880573\n"
     ]
    }
   ],
   "source": [
    "print(XTrain_scaled[0], yTest[0])\n",
    "print(np.mean(yTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , -0.04596655, -0.0704312 ,  0.2746087 , -0.04316393,\n",
       "         0.099112  ,  0.1052247 , -0.0121125 , -0.01461041, -0.01039715,\n",
       "        -0.06560836, -0.01341189, -0.02359606, -0.02641304]])"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = sklearn.linear_model.LogisticRegression(class_weight = \"balanced\")\n",
    "model2.fit(XTrain_scaled, yTrain)\n",
    "model2.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5666907096488535\n",
      "0.5671436605636443\n"
     ]
    }
   ],
   "source": [
    "y_pred = model2.predict(XTest_scaled)\n",
    "TestAcc = np.mean(yTest == y_pred)\n",
    "print(TestAcc)\n",
    "TrainAcc = np.mean(yTrain == model2.predict(XTrain_scaled))\n",
    "print(Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19139 17345 43330 60213\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[19139, 17345],\n",
       "       [43330, 60213]])"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TN, FP, FN, TP = sklearn.metrics.confusion_matrix(yTest, model2.predict(XTest_scaled)).ravel()\n",
    "print(TN, FP, FN, TP)\n",
    "sklearn.metrics.confusion_matrix(yTest, model2.predict(XTest_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.46475142, 1.77545962, 7.78040038])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "resp_time_lst = [d['resp_time'] / 1000 / 60 / 60 / 24 for d in reviews_with_responses]\n",
    "np.quantile(resp_time_lst, [0.25, 0.5, 0.75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resp_time_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Montour WMA - Idaho Fish and Game',\n",
       " 'address': 'Montour WMA - Idaho Fish and Game, Montour Rd, Emmett, ID 83617',\n",
       " 'gmap_id': '0x54af0dfadab474e1:0x3ae5c949132941d8',\n",
       " 'description': None,\n",
       " 'latitude': 43.9295808,\n",
       " 'longitude': -116.3333273,\n",
       " 'category': ['Hunting area'],\n",
       " 'avg_rating': 4.4,\n",
       " 'num_of_reviews': 17,\n",
       " 'price': None,\n",
       " 'hours': None,\n",
       " 'MISC': {'Accessibility': ['Wheelchair accessible parking lot']},\n",
       " 'state': None,\n",
       " 'relative_results': ['0x54af0df970009eab:0x998e663a1d2ea45',\n",
       "  '0x54af0e08fb885aed:0xf626feadb2775442',\n",
       "  '0x54afa0ce7af7268b:0x4b98fe1767238dc4',\n",
       "  '0x54afc0324c4ca65b:0x808e759ecacfab1c',\n",
       "  '0x54afb8ee4d09b825:0x50112376cec8c0ff'],\n",
       " 'url': 'https://www.google.com/maps/place//data=!4m2!3m1!1s0x54af0dfadab474e1:0x3ae5c949132941d8?authuser=-1&hl=en&gl=us'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bizs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_id': '108480743392575424354',\n",
       " 'name': 'Dan Shadix',\n",
       " 'time': 1525705287828,\n",
       " 'rating': 5,\n",
       " 'text': 'Love this float on paddle boards.  Nice flat water and fairly slow.',\n",
       " 'pics': None,\n",
       " 'resp': None,\n",
       " 'gmap_id': '0x54af0dfadab474e1:0x3ae5c949132941d8'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_reviews = defaultdict(lambda: None)\n",
    "for r in reviews:\n",
    "    if r['resp'] and 'time' in r['resp']:\n",
    "        business_reviews[r['gmap_id']] = r['resp']['time'] - r['time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31616"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniq_vals, counts = np.unique([r['gmap_id'] for r in reviews], return_counts=True)\n",
    "len(uniq_vals[counts > 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3892636"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8122002673766568"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "31616/3892636*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def feature(millisec):\n",
    "    previousHours = []\n",
    "    #### time of year feature\n",
    "    for i in [24,24*7,24*7*365]:\n",
    "        previousHour = hour - i\n",
    "        previousHourExists = previousHour in hourly\n",
    "        if previousHourExists:\n",
    "            previousHours += [hourly[previousHour]]\n",
    "        else:\n",
    "            previousHours += [0]\n",
    "    return previousHours"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
