{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages\n",
    "import gzip\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(path):\n",
    "  g = gzip.open(path, 'r')\n",
    "  for l in g:\n",
    "    yield json.loads(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "review_filepath = \"../assignment2/review-Idaho.json.gz\"\n",
    "meta_filepath = \"../assignment2/meta-Idaho.json.gz\"\n",
    "\n",
    "reviews = []\n",
    "bizs = []\n",
    "for l in parse(review_filepath):\n",
    "    reviews.append(l)\n",
    "\n",
    "for l in parse(meta_filepath):\n",
    "    bizs.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from eda notebook\n",
    "\n",
    "b_avg_ratings = []\n",
    "b_num_reviews = []\n",
    "b_num_similar_bizs = []\n",
    "b_prices = []\n",
    "b_states = [] # i.e. None, 'Closed ⋅ Opens 10AM Fri' , 'Permanently closed' , 'Open ⋅ Closes 5PM' , maybe more types\n",
    "# ^ only listed once per biz, not at time of each review meaning the open/closed is not always true for every one of it's reviews, but maybe 'permanently closed' would help predict time\n",
    "b_has_prices = []\n",
    "for b in bizs:\n",
    "    b_avg_ratings.append(b['avg_rating'])\n",
    "    b_num_reviews.append(b['num_of_reviews'])\n",
    "    b_num_similar_bizs.append((0 if b['relative_results'] == None else len(b['relative_results'])))\n",
    "    if b['price'] == None:\n",
    "        b_has_prices.append(0)\n",
    "        b_prices.append(b['price']) # missing data\n",
    "    else:\n",
    "        b_has_prices.append(1)\n",
    "        b_prices.append(len(b['price']))\n",
    "    try:\n",
    "        b_states.append(b['state']) # maybe split into counts of each one when analyzing\n",
    "    except Exception as e:\n",
    "        b_states.append(None)\n",
    "r_ratings = []\n",
    "r_time_difs = []\n",
    "r_num_pics = []\n",
    "r_has_response = []\n",
    "r_resp_times = []\n",
    "for r in reviews:\n",
    "    r_ratings.append(r['rating'])\n",
    "    try:\n",
    "        r_time_difs.append(r['resp']['time'] - r['time']) #Nones might cause errors or NaNs, handle later\n",
    "        r_resp_times.append(r['resp']['time'])\n",
    "        r_has_response.append(1)\n",
    "    except Exception as e:\n",
    "        r_time_difs.append(None)\n",
    "        r_resp_times.append(None)\n",
    "        r_has_response.append(0)\n",
    "    try:\n",
    "        r_num_pics.append(len(r['pics']))\n",
    "    except Exception as e:\n",
    "        r_num_pics.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "729928\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "700132"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_with_responses = [review for review in reviews if review.get(\"resp\")]\n",
    "print(len(reviews_with_responses))\n",
    "reviews_with_responses = [review for review in reviews \n",
    "                          if ((review.get(\"resp\")) and (review['resp']['time'] - review['time'] > 0))]\n",
    "len(reviews_with_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in reviews_with_responses:\n",
    "    r['resp_time'] = r['resp']['time'] - r['time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_id': '115114032166130224762',\n",
       " 'name': 'Mariah Schaeffer',\n",
       " 'time': 1589989743506,\n",
       " 'rating': 5,\n",
       " 'text': 'Kevin and Shannon are amazing! They were very sweet and made the job fast! Also they are one of the cheeper junk removal services! I will for sure use again!',\n",
       " 'pics': None,\n",
       " 'resp': {'time': 1591139557205,\n",
       "  'text': 'Thank you for hiring us for your junk removal!'},\n",
       " 'gmap_id': '0x54afb4c19c4bffff:0x9389114191ca2781',\n",
       " 'resp_time': 1149813699}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_with_responses[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model #1 - linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature(d):\n",
    "    feat = [1]\n",
    "    try:\n",
    "        text_length = len(d['text'])\n",
    "    except (KeyError, TypeError):\n",
    "        text_length = 0 \n",
    "    feat.append(text_length)\n",
    "    feat.append(d.get('rating', 0))\n",
    "    feat.append(d.get('time', 0))\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = [feature(r) for r in reviews_with_responses]\n",
    "y = [r['resp_time'] for r in reviews_with_responses]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression(fit_intercept=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LinearRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LinearRegression(fit_intercept=False)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression(fit_intercept=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = sklearn.linear_model.LinearRegression(fit_intercept=False)\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3744326911207206e+20"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X)\n",
    "sse = sum([x**2 for x in (y - y_pred)])\n",
    "mse = sse / len(y)\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat(d):\n",
    "    feat = [1]\n",
    "    try:\n",
    "        text_length = len(d['text'])\n",
    "    except (KeyError, TypeError):\n",
    "        text_length = 0 \n",
    "    feat.append(text_length)\n",
    "    feat.append(d.get('rating', 0))\n",
    "    feat.append(d.get('time', 0))\n",
    "    feat.append(d.get('resp_time', 0))\n",
    "    gmap_id = d.get('gmap_id')\n",
    "    if gmap_id in b and isinstance(b[gmap_id], dict):\n",
    "        avg_rating = b[gmap_id].get('avg_rating', 0)\n",
    "    else:\n",
    "        avg_rating = 0  # Default if gmap_id is invalid or not in b\n",
    "    \n",
    "    feat.append(avg_rating)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat2(d):\n",
    "    feat = [1]\n",
    "    feat.append(d.get('avg_rating', 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [feat(r) for r in reviews_with_responses]\n",
    "y = [r['resp_time'] for r in reviews_with_responses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " ...]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[None None None ... None None None].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model2 \u001b[38;5;241m=\u001b[39m sklearn\u001b[38;5;241m.\u001b[39mlinear_model\u001b[38;5;241m.\u001b[39mLinearRegression(fit_intercept\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_base.py:609\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    605\u001b[0m n_jobs_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs\n\u001b[1;32m    607\u001b[0m accept_sparse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositive \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 609\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    618\u001b[0m has_sw \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    619\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_sw:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:650\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    648\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 650\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/validation.py:1301\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1296\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1297\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1298\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1299\u001b[0m     )\n\u001b[0;32m-> 1301\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1303\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1304\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1306\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1307\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1308\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_writeable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1309\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1315\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1316\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1318\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m   1320\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/validation.py:1050\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1043\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1044\u001b[0m             msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1045\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1046\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1047\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1048\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1049\u001b[0m             )\n\u001b[0;32m-> 1050\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(array\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkind\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSV\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1053\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1054\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1055\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1056\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[None None None ... None None None].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "model2 = sklearn.linear_model.LinearRegression(fit_intercept=False)\n",
    "model2.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3744326911207206e+20"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X)\n",
    "sse = sum([x**2 for x in (y - y_pred)])\n",
    "mse = sse / len(y)\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.46475142, 1.77545962, 7.78040038])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "resp_time_lst = [d['resp_time'] / 1000 / 60 / 60 / 24 for d in reviews_with_responses]\n",
    "np.quantile(resp_time_lst, [0.25, 0.5, 0.75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13.308028923611111,\n",
       " 6.845580023148147,\n",
       " 40.164034745370365,\n",
       " 308.1323496875,\n",
       " 0.18931494212962963,\n",
       " 0.9109248726851852,\n",
       " 248.98713701388888,\n",
       " 6.388242731481481,\n",
       " 336.3063022453704,\n",
       " 313.9500467824074,\n",
       " 10.783241087962963,\n",
       " 31.447186747685183,\n",
       " 152.15838922453705,\n",
       " 1.2255548032407406,\n",
       " 72.23770158564815,\n",
       " 0.013149722222222222,\n",
       " 0.02466456018518519,\n",
       " 12.749598182870372,\n",
       " 0.1768450810185185,\n",
       " 0.7330953587962963,\n",
       " 3.2862648379629626,\n",
       " 0.14779,\n",
       " 0.07627248842592593,\n",
       " 0.08757020833333334,\n",
       " 0.01581945601851852,\n",
       " 13.260755254629629,\n",
       " 0.013149722222222222,\n",
       " 13.260755254629629,\n",
       " 72.23770158564815,\n",
       " 3.2862648379629626,\n",
       " 10.783241087962963,\n",
       " 0.08757020833333334,\n",
       " 0.02035837962962963,\n",
       " 0.7217396875,\n",
       " 12.749598182870372,\n",
       " 1.2255548032407406,\n",
       " 0.32887030092592595,\n",
       " 18.36666894675926,\n",
       " 0.10357716435185182,\n",
       " 340.26908748842595,\n",
       " 0.009868726851851852,\n",
       " 0.019788530092592592,\n",
       " 0.031149456018518522,\n",
       " 0.01042212962962963,\n",
       " 0.2061985300925926,\n",
       " 314.0200500925926,\n",
       " 0.003111643518518519,\n",
       " 0.12248881944444444,\n",
       " 0.5727105324074074,\n",
       " 0.5505841087962963,\n",
       " 0.22116662037037035,\n",
       " 0.8914246064814814,\n",
       " 271.1132571064815,\n",
       " 15.053956631944443,\n",
       " 5.799793738425926,\n",
       " 2.660038090277778,\n",
       " 0.9417605092592591,\n",
       " 0.6595068171296297,\n",
       " 2.782305486111111,\n",
       " 0.017454050925925925,\n",
       " 1.7822657291666666,\n",
       " 0.7582269791666668,\n",
       " 4.576512685185185,\n",
       " 5.438199166666667,\n",
       " 0.11031843750000002,\n",
       " 5.448031979166667,\n",
       " 5.455658587962962,\n",
       " 0.7727973611111111,\n",
       " 0.029776875000000005,\n",
       " 4.5782182175925925,\n",
       " 6.568457106481482,\n",
       " 0.9780967592592592,\n",
       " 0.14090195601851854,\n",
       " 2.7672609375,\n",
       " 0.39854585648148144,\n",
       " 0.7239502893518518,\n",
       " 0.8799820254629629,\n",
       " 0.08880396990740741,\n",
       " 2.8506178125,\n",
       " 1.6273750810185186,\n",
       " 24.161966423611116,\n",
       " 0.8631921643518519,\n",
       " 3.8043167592592595,\n",
       " 25.94495048611111,\n",
       " 4.956276030092593,\n",
       " 0.13135081018518519,\n",
       " 1.2019688425925925,\n",
       " 0.04090277777777778,\n",
       " 0.6173549884259258,\n",
       " 25.83132961805556,\n",
       " 0.7051095601851851,\n",
       " 4.540240011574074,\n",
       " 15.019978101851853,\n",
       " 2.788943055555556,\n",
       " 0.7617269907407408,\n",
       " 40.030222476851854,\n",
       " 0.03828575231481481,\n",
       " 35.90073744212963,\n",
       " 7.993965752314814,\n",
       " 16.70001466435185,\n",
       " 433.75325521990743,\n",
       " 809.2711814583332,\n",
       " 848.8038972337963,\n",
       " 1164.2952896064814,\n",
       " 129.8127300925926,\n",
       " 0.809385625,\n",
       " 0.024507847222222223,\n",
       " 0.03797653935185185,\n",
       " 0.07239899305555557,\n",
       " 0.9637605787037038,\n",
       " 0.042720752314814814,\n",
       " 35.75194459490741,\n",
       " 0.2959859837962963,\n",
       " 111.08925498842592,\n",
       " 1003.6405256597222,\n",
       " 244.68665342592593,\n",
       " 469.1495419212963,\n",
       " 476.9289663773148,\n",
       " 567.7949864699075,\n",
       " 343.94005680555557,\n",
       " 1720.9247938194446,\n",
       " 752.3616138657408,\n",
       " 699.8682593634259,\n",
       " 980.988732337963,\n",
       " 1035.815382650463,\n",
       " 2085.0435076041667,\n",
       " 905.8789816782406,\n",
       " 613.8299157291666,\n",
       " 0.04727752314814815,\n",
       " 0.010226759259259258,\n",
       " 0.01420783564814815,\n",
       " 0.06615287037037038,\n",
       " 0.04232432870370371,\n",
       " 0.4388461458333333,\n",
       " 0.062215682870370374,\n",
       " 0.07025456018518518,\n",
       " 0.5313598726851853,\n",
       " 1.0009629629629628,\n",
       " 0.1760667361111111,\n",
       " 1.108777372685185,\n",
       " 0.8120342013888888,\n",
       " 1.0077310416666665,\n",
       " 1.594409710648148,\n",
       " 0.10533093750000001,\n",
       " 1.704942303240741,\n",
       " 1.0030325347222222,\n",
       " 666.4737662615742,\n",
       " 0.06776693287037037,\n",
       " 0.19470319444444442,\n",
       " 0.7940530439814816,\n",
       " 685.925716400463,\n",
       " 7.932876689814815,\n",
       " 78.95071554398147,\n",
       " 185.9624796412037,\n",
       " 1.965923449074074,\n",
       " 0.847257199074074,\n",
       " 374.9066226157408,\n",
       " 54.70576020833334,\n",
       " 693.112543935185,\n",
       " 384.45083290509257,\n",
       " 95.6390231712963,\n",
       " 8.317265324074073,\n",
       " 62.700977789351846,\n",
       " 80.76389185185185,\n",
       " 408.9231008217592,\n",
       " 408.54133114583334,\n",
       " 6.967215208333333,\n",
       " 395.6601541203704,\n",
       " 81.70252043981482,\n",
       " 166.70735695601851,\n",
       " 307.72823480324075,\n",
       " 592.5972484953704,\n",
       " 179.5533398148148,\n",
       " 172.83983621527776,\n",
       " 313.7531480902778,\n",
       " 0.05882349537037038,\n",
       " 307.7982844097222,\n",
       " 54.576508333333344,\n",
       " 47.40022631944444,\n",
       " 278.5704750925926,\n",
       " 307.64701196759256,\n",
       " 446.75300498842597,\n",
       " 185.62084354166666,\n",
       " 48.05162416666666,\n",
       " 56.36216226851852,\n",
       " 408.7523235416666,\n",
       " 84.84518410879629,\n",
       " 157.63072302083336,\n",
       " 275.6230993634259,\n",
       " 6.34815269675926,\n",
       " 102.56516887731482,\n",
       " 118.95022881944443,\n",
       " 755.7159003935185,\n",
       " 472.58613736111107,\n",
       " 248.42338988425925,\n",
       " 51.4111482175926,\n",
       " 33.7519650462963,\n",
       " 1.551618333333333,\n",
       " 180.68687538194445,\n",
       " 2.343799108796296,\n",
       " 0.013296006944444445,\n",
       " 24.011005208333334,\n",
       " 244.6118231134259,\n",
       " 171.61602144675928,\n",
       " 250.6624854861111,\n",
       " 151.67588269675926,\n",
       " 241.42944884259256,\n",
       " 194.68151672453703,\n",
       " 0.1729350810185185,\n",
       " 2.5355347569444446,\n",
       " 152.88040937499997,\n",
       " 22.56743559027778,\n",
       " 48.42293496527778,\n",
       " 11.651725497685185,\n",
       " 144.9401703125,\n",
       " 7.978628402777777,\n",
       " 0.03333747685185186,\n",
       " 2.9532390972222227,\n",
       " 1.8640077199074072,\n",
       " 3.882696550925926,\n",
       " 0.5741890972222222,\n",
       " 3.6497267592592593,\n",
       " 1.8640077199074072,\n",
       " 0.012331990740740739,\n",
       " 0.7936599652777779,\n",
       " 3.6497267592592593,\n",
       " 6.70416337962963,\n",
       " 1.4687560185185184,\n",
       " 7.045974467592593,\n",
       " 0.5741890972222222,\n",
       " 3.181868136574074,\n",
       " 0.7936599652777779,\n",
       " 6.729294201388888,\n",
       " 0.05964547453703704,\n",
       " 6.70416337962963,\n",
       " 0.8125977083333332,\n",
       " 3.720159560185186,\n",
       " 2.7525042939814814,\n",
       " 3.810229907407407,\n",
       " 0.011225914351851852,\n",
       " 2.8687578009259265,\n",
       " 1.8258758101851853,\n",
       " 1.02329,\n",
       " 0.022225717592592592,\n",
       " 10.748852557870372,\n",
       " 4.12638119212963,\n",
       " 1.1374444675925925,\n",
       " 1.9246176851851848,\n",
       " 2.6000480787037037,\n",
       " 2.949514513888889,\n",
       " 2.702114050925926,\n",
       " 0.834558888888889,\n",
       " 2.724910300925926,\n",
       " 2.940445162037037,\n",
       " 3.0463846180555554,\n",
       " 1.1556954745370371,\n",
       " 1.884265810185185,\n",
       " 2.991894247685185,\n",
       " 2.8899737268518515,\n",
       " 3.995507685185185,\n",
       " 1.895093287037037,\n",
       " 2.5372224074074077,\n",
       " 1.5765073726851853,\n",
       " 0.8765399884259258,\n",
       " 6.937409722222221,\n",
       " 3.9629497569444445,\n",
       " 2.6826283796296297,\n",
       " 3.8591953472222222,\n",
       " 10.460504016203704,\n",
       " 2.5893579166666667,\n",
       " 0.6627732060185185,\n",
       " 0.9573596874999999,\n",
       " 0.877172511574074,\n",
       " 0.1891779166666667,\n",
       " 0.015007488425925926,\n",
       " 385.12552915509264,\n",
       " 0.07362157407407408,\n",
       " 3.7768327083333335,\n",
       " 0.6085489467592592,\n",
       " 1.7825991550925926,\n",
       " 4.150896666666667,\n",
       " 1.0976451967592593,\n",
       " 1.9223002893518517,\n",
       " 0.050023194444444447,\n",
       " 2.935228101851852,\n",
       " 0.7276889351851851,\n",
       " 6.172550868055556,\n",
       " 0.07605186342592593,\n",
       " 0.44545415509259256,\n",
       " 3.896934988425926,\n",
       " 0.01608570601851852,\n",
       " 0.009435266203703703,\n",
       " 0.02689611111111111,\n",
       " 0.00955601851851852,\n",
       " 0.0035963657407407403,\n",
       " 0.012767708333333334,\n",
       " 0.010581168981481481,\n",
       " 0.21119912037037036,\n",
       " 0.012767708333333334,\n",
       " 0.01087898148148148,\n",
       " 0.566702673611111,\n",
       " 0.21119912037037036,\n",
       " 0.007579583333333333,\n",
       " 0.007572650462962963,\n",
       " 0.01701613425925926,\n",
       " 0.6738030439814815,\n",
       " 1.5504612384259258,\n",
       " 0.2768077662037037,\n",
       " 0.6738030439814815,\n",
       " 0.007458287037037037,\n",
       " 0.0068055787037037034,\n",
       " 0.566702673611111,\n",
       " 0.0357809375,\n",
       " 0.009330648148148149,\n",
       " 0.003671909722222222,\n",
       " 0.6933805092592592,\n",
       " 0.00857736111111111,\n",
       " 0.04127696759259259,\n",
       " 0.008051875,\n",
       " 0.06268097222222223,\n",
       " 186.12512598379627,\n",
       " 28.038423263888888,\n",
       " 0.007329398148148148,\n",
       " 0.020459791666666668,\n",
       " 0.00921619212962963,\n",
       " 0.0017598032407407408,\n",
       " 313.01671706018516,\n",
       " 0.283443599537037,\n",
       " 0.280961724537037,\n",
       " 0.2629885300925926,\n",
       " 0.16822637731481482,\n",
       " 0.0588921875,\n",
       " 0.6819474768518519,\n",
       " 0.3846962384259259,\n",
       " 0.007594421296296297,\n",
       " 0.004780706018518518,\n",
       " 0.007527893518518518,\n",
       " 0.01863236111111111,\n",
       " 0.016860891203703703,\n",
       " 0.04772931712962963,\n",
       " 0.12495055555555555,\n",
       " 0.016817430555555558,\n",
       " 0.2797515277777778,\n",
       " 0.004681273148148148,\n",
       " 5.021855810185185,\n",
       " 0.13750631944444444,\n",
       " 0.9249264930555556,\n",
       " 0.8452034259259259,\n",
       " 1.0458147569444445,\n",
       " 0.26580994212962966,\n",
       " 0.11155590277777777,\n",
       " 0.052810034722222225,\n",
       " 1.0991879861111111,\n",
       " 0.02191855324074074,\n",
       " 0.44182019675925926,\n",
       " 0.8829213194444444,\n",
       " 1.672200011574074,\n",
       " 0.2441286574074074,\n",
       " 1.0379226967592592,\n",
       " 0.008295648148148147,\n",
       " 0.40921621527777785,\n",
       " 1.0016068865740742,\n",
       " 0.798052025462963,\n",
       " 1.0248361574074074,\n",
       " 2.0768226967592596,\n",
       " 0.029458356481481485,\n",
       " 0.03716070601851852,\n",
       " 21.822281851851855,\n",
       " 0.024929120370370372,\n",
       " 0.022911446759259258,\n",
       " 10.881201747685184,\n",
       " 0.009204085648148149,\n",
       " 6.633202569444445,\n",
       " 0.16869629629629632,\n",
       " 0.6398847453703703,\n",
       " 0.24649413194444444,\n",
       " 0.6829715972222222,\n",
       " 5.286673703703704,\n",
       " 1.7077013310185183,\n",
       " 0.6532655902777778,\n",
       " 0.1216014699074074,\n",
       " 3.6970067013888888,\n",
       " 1.621863425925926,\n",
       " 73.9744705787037,\n",
       " 97.21427778935184,\n",
       " 33.969893587962964,\n",
       " 7.65683105324074,\n",
       " 22.09441033564815,\n",
       " 10.160870694444444,\n",
       " 0.43540399305555555,\n",
       " 219.73755736111113,\n",
       " 4.618200567129629,\n",
       " 3.6113675925925928,\n",
       " 171.39526527777778,\n",
       " 71.3405140162037,\n",
       " 16.512817060185185,\n",
       " 136.3545643634259,\n",
       " 0.02773986111111111,\n",
       " 1.2956348958333332,\n",
       " 0.5995513425925926,\n",
       " 15.602575405092592,\n",
       " 2.4409601273148147,\n",
       " 1.8840599537037035,\n",
       " 10.807565972222221,\n",
       " 0.018761608796296295,\n",
       " 0.7643562962962963,\n",
       " 34.245383842592595,\n",
       " 0.04534548611111111,\n",
       " 0.1296547800925926,\n",
       " 0.015916840277777778,\n",
       " 47.24693662037038,\n",
       " 5.823017974537038,\n",
       " 0.034605,\n",
       " 353.8936734027778,\n",
       " 0.014749375,\n",
       " 0.0502196875,\n",
       " 349.958779212963,\n",
       " 0.008599363425925927,\n",
       " 953.0984144444445,\n",
       " 2256.2096908333333,\n",
       " 0.2767804976851852,\n",
       " 953.1181490509258,\n",
       " 872.1546029976852,\n",
       " 1593.3134834606478,\n",
       " 1593.3369410185185,\n",
       " 87.19509881944445,\n",
       " 69.20332319444444,\n",
       " 0.05944519675925925,\n",
       " 0.004382152777777777,\n",
       " 0.0542847800925926,\n",
       " 8.782722604166667,\n",
       " 7.005413784722222,\n",
       " 1.0641034490740742,\n",
       " 0.1865187962962963,\n",
       " 0.143740625,\n",
       " 0.049855231481481486,\n",
       " 32.34439951388889,\n",
       " 47.67047374999999,\n",
       " 22.55781564814815,\n",
       " 0.04891865740740741,\n",
       " 30.838167314814815,\n",
       " 82.9656633912037,\n",
       " 1.421267986111111,\n",
       " 1.7232530208333332,\n",
       " 10.499545694444445,\n",
       " 72.61574010416668,\n",
       " 0.18919770833333335,\n",
       " 0.3754925115740741,\n",
       " 241.69073248842594,\n",
       " 0.9213744444444444,\n",
       " 0.5342679976851852,\n",
       " 10.225179675925926,\n",
       " 2.756323865740741,\n",
       " 0.6886777199074073,\n",
       " 0.8847421990740739,\n",
       " 12.004425243055557,\n",
       " 2.756345081018519,\n",
       " 11.629884837962964,\n",
       " 1.041615763888889,\n",
       " 13.801082511574075,\n",
       " 13.901643796296296,\n",
       " 13.91825234953704,\n",
       " 13.860085821759261,\n",
       " 11.908466435185185,\n",
       " 13.864650069444446,\n",
       " 13.89300732638889,\n",
       " 13.84339645833333,\n",
       " 0.0521666087962963,\n",
       " 1.5900413078703703,\n",
       " 0.726046388888889,\n",
       " 0.23892565972222224,\n",
       " 0.10308910879629629,\n",
       " 0.4680739236111111,\n",
       " 1.0057713541666666,\n",
       " 4.954956435185185,\n",
       " 10.672870405092594,\n",
       " 6.085337523148149,\n",
       " 1.7129925694444443,\n",
       " 5.977601493055555,\n",
       " 3.1483600694444447,\n",
       " 3.353405243055555,\n",
       " 10.56954587962963,\n",
       " 14.51132954861111,\n",
       " 29.76087736111111,\n",
       " 17.63345289351852,\n",
       " 11.491342291666669,\n",
       " 9.19338990740741,\n",
       " 0.742014513888889,\n",
       " 2.1931241550925926,\n",
       " 85.73400916666667,\n",
       " 4.90183693287037,\n",
       " 1.237770925925926,\n",
       " 0.06262773148148147,\n",
       " 0.5114348032407406,\n",
       " 0.6326434259259259,\n",
       " 1.206306087962963,\n",
       " 3.6712901736111117,\n",
       " 4.281068136574074,\n",
       " 1.0407117129629628,\n",
       " 0.02366236111111111,\n",
       " 1.081615787037037,\n",
       " 0.2509225231481481,\n",
       " 0.03572423611111111,\n",
       " 0.0716257638888889,\n",
       " 1.058212696759259,\n",
       " 0.11548978009259257,\n",
       " 0.05092586805555555,\n",
       " 0.011774074074074074,\n",
       " 0.061921597222222215,\n",
       " 22.837065787037034,\n",
       " 0.8319543749999999,\n",
       " 8.917830694444445,\n",
       " 0.6520475462962964,\n",
       " 0.13874063657407407,\n",
       " 2.0573036921296297,\n",
       " 1.544270532407407,\n",
       " 3.096537210648148,\n",
       " 5.605472789351851,\n",
       " 0.42490605324074077,\n",
       " 4.967997592592593,\n",
       " 3.135377638888889,\n",
       " 12.001614247685184,\n",
       " 7.9522809375,\n",
       " 5.337053877314815,\n",
       " 0.11313287037037038,\n",
       " 0.5127420601851852,\n",
       " 70.5619784375,\n",
       " 0.14781265046296296,\n",
       " 0.7390377546296296,\n",
       " 0.4698294791666666,\n",
       " 56.449774884259256,\n",
       " 139.97487917824074,\n",
       " 3.133370405092592,\n",
       " 0.11021931712962964,\n",
       " 0.13129623842592594,\n",
       " 54.5334327662037,\n",
       " 155.38294778935185,\n",
       " 1117.1522915624998,\n",
       " 5.593398634259259,\n",
       " 29.146238993055558,\n",
       " 0.32659875,\n",
       " 31.29173300925926,\n",
       " 0.29235327546296297,\n",
       " 94.25161125000001,\n",
       " 91.20515863425926,\n",
       " 0.32042454861111114,\n",
       " 77.97660136574073,\n",
       " 0.06020914351851852,\n",
       " 129.28718438657407,\n",
       " 0.6027801736111111,\n",
       " 0.05756287037037036,\n",
       " 55.257999317129624,\n",
       " 0.5775682175925926,\n",
       " 13.55992716435185,\n",
       " 135.87181524305555,\n",
       " 170.29918814814815,\n",
       " 136.82372288194443,\n",
       " 215.1794918634259,\n",
       " 0.008472743055555555,\n",
       " 135.87613947916665,\n",
       " 234.87540207175925,\n",
       " 79.26837299768519,\n",
       " 2.352421273148148,\n",
       " 0.20450503472222223,\n",
       " 248.11027600694445,\n",
       " 77.27738484953703,\n",
       " 47.88685846064815,\n",
       " 5.922117372685186,\n",
       " 0.2973414583333333,\n",
       " 0.11284552083333332,\n",
       " 0.24389385416666667,\n",
       " 0.04948684027777778,\n",
       " 0.7411170601851852,\n",
       " 163.66020149305555,\n",
       " 137.16952417824075,\n",
       " 74.43358637731481,\n",
       " 153.92172868055553,\n",
       " 1553.3382246759263,\n",
       " 12.224363101851852,\n",
       " 349.0607244675926,\n",
       " 1025.5590409027777,\n",
       " 191.16113837962965,\n",
       " 576.4958106134259,\n",
       " 150.3780832986111,\n",
       " 0.14468133101851852,\n",
       " 94.402565,\n",
       " 0.07762818287037036,\n",
       " 376.0863321296297,\n",
       " 972.2370629513889,\n",
       " 324.2582508101852,\n",
       " 74.71281598379629,\n",
       " 0.04614677083333334,\n",
       " 420.42599678240737,\n",
       " 1422.2322560416667,\n",
       " 35.827441469907406,\n",
       " 0.12772854166666667,\n",
       " 0.29961053240740737,\n",
       " 5.040179421296296,\n",
       " 2.047410486111111,\n",
       " 0.9923771412037037,\n",
       " 14.992809340277779,\n",
       " 17.749105671296295,\n",
       " 2.103994074074074,\n",
       " 5.100837835648148,\n",
       " 4.240916238425926,\n",
       " 3.1523131944444445,\n",
       " 25.49383466435185,\n",
       " 0.7532443518518518,\n",
       " 7.134037233796296,\n",
       " 5.9723575115740735,\n",
       " 6.134882233796296,\n",
       " 0.05575586805555555,\n",
       " 7.8022612152777775,\n",
       " 8.145788125000001,\n",
       " 0.9156812962962962,\n",
       " 35.90850763888889,\n",
       " 0.8741710763888887,\n",
       " 54.94268015046297,\n",
       " 154.71305170138888,\n",
       " 25.714370266203705,\n",
       " 0.7995920138888888,\n",
       " 68.14831782407407,\n",
       " 0.009266770833333333,\n",
       " 0.04755532407407407,\n",
       " 114.9793091550926,\n",
       " 34.9335831712963,\n",
       " 35.91484572916667,\n",
       " 20.65705287037037,\n",
       " 146.67372375000002,\n",
       " 65.80504190972223,\n",
       " 36.02910802083334,\n",
       " 52.81028868055555,\n",
       " 148.8314083449074,\n",
       " 35.72638432870371,\n",
       " 36.05460065972222,\n",
       " 58.04899601851852,\n",
       " 163.99629802083334,\n",
       " 0.06268502314814814,\n",
       " 63.642367523148145,\n",
       " 0.12030201388888888,\n",
       " 0.007768796296296298,\n",
       " 34.44044065972222,\n",
       " 68.85820994212962,\n",
       " 0.007406909722222223,\n",
       " 0.007889201388888888,\n",
       " 0.04088847222222223,\n",
       " 0.005551099537037037,\n",
       " 0.6275318981481481,\n",
       " 14.770895289351849,\n",
       " 0.018633483796296296,\n",
       " 0.037185289351851857,\n",
       " 2.8716674652777776,\n",
       " 0.43547099537037043,\n",
       " 71.37855283564814,\n",
       " 0.04529357638888889,\n",
       " 0.5673777199074074,\n",
       " 0.5022153125,\n",
       " 122.78565516203706,\n",
       " 0.005689016203703705,\n",
       " 8.818281828703705,\n",
       " 0.6376658912037038,\n",
       " 0.49244011574074076,\n",
       " 1.7565311342592593,\n",
       " 6.447036481481482,\n",
       " 0.01873423611111111,\n",
       " 28.08144866898148,\n",
       " 6.890423020833334,\n",
       " 3.8298398379629632,\n",
       " 27.97713596064814,\n",
       " 0.10902159722222222,\n",
       " 6.447036481481482,\n",
       " 3.8298398379629632,\n",
       " 82.09951408564815,\n",
       " 0.10118229166666666,\n",
       " 6.387627037037038,\n",
       " 125.94004966435183,\n",
       " 34.58098231481481,\n",
       " 96.07463489583334,\n",
       " 2.669088148148148,\n",
       " 0.4464515625,\n",
       " 5.0993800347222225,\n",
       " 0.3860078587962963,\n",
       " 0.3681425231481481,\n",
       " 6.410148553240739,\n",
       " 0.09953769675925926,\n",
       " 15.227298715277776,\n",
       " 100.8686271412037,\n",
       " 0.35393990740740744,\n",
       " 0.5446355439814815,\n",
       " 36.92062174768518,\n",
       " 0.046183530092592594,\n",
       " 2.233561076388889,\n",
       " 0.6918540162037036,\n",
       " 0.3167429513888889,\n",
       " 50.20342003472223,\n",
       " 0.4703651620370371,\n",
       " 32.868644305555556,\n",
       " 2.593227523148148,\n",
       " 0.06808532407407407,\n",
       " 0.027021435185185187,\n",
       " 20.632385324074075,\n",
       " 0.056836423611111124,\n",
       " 21.89133763888889,\n",
       " 177.76524458333333,\n",
       " 0.6896953703703703,\n",
       " 0.011956550925925928,\n",
       " 0.13802487268518518,\n",
       " 0.013456921296296298,\n",
       " 0.008213344907407407,\n",
       " 0.02069934027777778,\n",
       " 0.0513425925925926,\n",
       " 1.0185816666666667,\n",
       " 0.692253761574074,\n",
       " 0.008009791666666667,\n",
       " 55.632056527777785,\n",
       " 0.008214166666666666,\n",
       " 69.82467542824075,\n",
       " 40.056886666666664,\n",
       " 1.0036217592592591,\n",
       " 0.05727688657407407,\n",
       " 0.6100562731481481,\n",
       " 0.006998113425925926,\n",
       " 0.5448739699074074,\n",
       " 0.009157268518518518,\n",
       " 0.10950365740740742,\n",
       " 2.323624340277778,\n",
       " 0.39742396990740736,\n",
       " 0.009048912037037038,\n",
       " 0.008654027777777778,\n",
       " 0.033129733796296294,\n",
       " 0.06194737268518519,\n",
       " 17.06099528935185,\n",
       " 0.00970513888888889,\n",
       " 0.023642777777777776,\n",
       " 0.06458678240740741,\n",
       " 0.04967420138888889,\n",
       " 0.054864895833333344,\n",
       " 0.6579354976851851,\n",
       " 0.5403777777777777,\n",
       " 0.008513599537037038,\n",
       " 41.04629320601852,\n",
       " 0.9462982291666667,\n",
       " 0.4733260532407408,\n",
       " 0.1715413541666667,\n",
       " 2.8133916087962962,\n",
       " 0.014207881944444443,\n",
       " 0.010448622685185184,\n",
       " 34.01223924768518,\n",
       " 0.018189733796296296,\n",
       " 0.45822064814814817,\n",
       " 0.1736338425925926,\n",
       " 0.0634109837962963,\n",
       " 0.41126614583333326,\n",
       " 0.022202233796296295,\n",
       " 0.023194606481481483,\n",
       " 0.05775128472222222,\n",
       " 0.4703639583333334,\n",
       " 0.15754422453703704,\n",
       " 0.013664351851851851,\n",
       " 0.041556064814814817,\n",
       " 0.12811442129629627,\n",
       " 0.11823510416666667,\n",
       " 11.610710034722223,\n",
       " 0.12973548611111113,\n",
       " 0.04634704861111111,\n",
       " 0.3372704166666667,\n",
       " 0.4162228935185186,\n",
       " 4.2058464814814815,\n",
       " 4.276642106481481,\n",
       " 2.122319710648148,\n",
       " 0.4177422337962963,\n",
       " 0.048134953703703694,\n",
       " 111.3830693287037,\n",
       " 2.156163634259259,\n",
       " 0.1269897800925926,\n",
       " 0.03627814814814815,\n",
       " 9.02911943287037,\n",
       " 0.14131968749999999,\n",
       " 4.276908275462962,\n",
       " 0.007638020833333333,\n",
       " 6.003152997685185,\n",
       " 0.008813981481481482,\n",
       " 0.02154736111111111,\n",
       " 5.022193541666667,\n",
       " 0.8022496874999999,\n",
       " 1.0707045717592594,\n",
       " 0.10061903935185186,\n",
       " 0.09431041666666666,\n",
       " 2.215393773148148,\n",
       " 3.013300104166667,\n",
       " 20.0627259375,\n",
       " 31.711197708333334,\n",
       " 0.11061256944444443,\n",
       " 1.6612307523148149,\n",
       " 13.308028923611111,\n",
       " 6.845580023148147,\n",
       " 40.164034745370365,\n",
       " 308.1323496875,\n",
       " 0.18931494212962963,\n",
       " 0.9109248726851852,\n",
       " 248.98713701388888,\n",
       " 6.388242731481481,\n",
       " 336.3063022453704,\n",
       " 313.9500467824074,\n",
       " 10.783241087962963,\n",
       " 31.447186747685183,\n",
       " 152.15838922453705,\n",
       " 1.2255548032407406,\n",
       " 72.23770158564815,\n",
       " 0.013149722222222222,\n",
       " 0.02466456018518519,\n",
       " 12.749598182870372,\n",
       " 0.1768450810185185,\n",
       " 0.7330953587962963,\n",
       " 3.2862648379629626,\n",
       " 0.14779,\n",
       " 0.07627248842592593,\n",
       " 0.08757020833333334,\n",
       " 0.01581945601851852,\n",
       " 13.260755254629629,\n",
       " 0.013149722222222222,\n",
       " 13.260755254629629,\n",
       " 72.23770158564815,\n",
       " 3.2862648379629626,\n",
       " 10.783241087962963,\n",
       " 0.08757020833333334,\n",
       " 0.02035837962962963,\n",
       " 0.7217396875,\n",
       " 12.749598182870372,\n",
       " 1.2255548032407406,\n",
       " 0.32887030092592595,\n",
       " 18.36666894675926,\n",
       " 0.10357716435185182,\n",
       " 340.26908748842595,\n",
       " 0.009868726851851852,\n",
       " 0.019788530092592592,\n",
       " 0.031149456018518522,\n",
       " 0.01042212962962963,\n",
       " 0.2061985300925926,\n",
       " 314.0200500925926,\n",
       " 0.003111643518518519,\n",
       " 0.12248881944444444,\n",
       " 0.5727105324074074,\n",
       " 0.5505841087962963,\n",
       " 0.22116662037037035,\n",
       " 0.8914246064814814,\n",
       " 271.1132571064815,\n",
       " 15.053956631944443,\n",
       " 5.799793738425926,\n",
       " 2.660038090277778,\n",
       " 0.9417605092592591,\n",
       " 0.6595068171296297,\n",
       " 2.782305486111111,\n",
       " 0.017454050925925925,\n",
       " 1.7822657291666666,\n",
       " 0.7582269791666668,\n",
       " 4.576512685185185,\n",
       " 5.438199166666667,\n",
       " 0.11031843750000002,\n",
       " 5.448031979166667,\n",
       " 5.455658587962962,\n",
       " 0.7727973611111111,\n",
       " 0.029776875000000005,\n",
       " 4.5782182175925925,\n",
       " 6.568457106481482,\n",
       " 0.9780967592592592,\n",
       " 0.14090195601851854,\n",
       " 2.7672609375,\n",
       " 0.39854585648148144,\n",
       " 0.7239502893518518,\n",
       " 0.8799820254629629,\n",
       " 0.08880396990740741,\n",
       " 2.8506178125,\n",
       " 1.6273750810185186,\n",
       " 24.161966423611116,\n",
       " 0.8631921643518519,\n",
       " 3.8043167592592595,\n",
       " 25.94495048611111,\n",
       " 4.956276030092593,\n",
       " 0.13135081018518519,\n",
       " 1.2019688425925925,\n",
       " 0.04090277777777778,\n",
       " 0.6173549884259258,\n",
       " 25.83132961805556,\n",
       " 0.7051095601851851,\n",
       " 4.540240011574074,\n",
       " 15.019978101851853,\n",
       " 2.788943055555556,\n",
       " 0.7617269907407408,\n",
       " 40.030222476851854,\n",
       " 0.03828575231481481,\n",
       " 35.90073744212963,\n",
       " 7.993965752314814,\n",
       " 16.70001466435185,\n",
       " 433.75325521990743,\n",
       " 809.2711814583332,\n",
       " 848.8038972337963,\n",
       " 1164.2952896064814,\n",
       " 129.8127300925926,\n",
       " 0.809385625,\n",
       " 0.024507847222222223,\n",
       " 0.03797653935185185,\n",
       " 0.07239899305555557,\n",
       " 0.9637605787037038,\n",
       " 0.042720752314814814,\n",
       " 35.75194459490741,\n",
       " 0.2959859837962963,\n",
       " 111.08925498842592,\n",
       " 1003.6405256597222,\n",
       " 244.68665342592593,\n",
       " 469.1495419212963,\n",
       " 476.9289663773148,\n",
       " 567.7949864699075,\n",
       " 343.94005680555557,\n",
       " 1720.9247938194446,\n",
       " 752.3616138657408,\n",
       " 699.8682593634259,\n",
       " 980.988732337963,\n",
       " 1035.815382650463,\n",
       " 2085.0435076041667,\n",
       " 905.8789816782406,\n",
       " 613.8299157291666,\n",
       " 0.04727752314814815,\n",
       " 0.010226759259259258,\n",
       " 0.01420783564814815,\n",
       " 0.06615287037037038,\n",
       " 0.04232432870370371,\n",
       " 0.4388461458333333,\n",
       " 0.062215682870370374,\n",
       " 0.07025456018518518,\n",
       " 0.5313598726851853,\n",
       " 1.0009629629629628,\n",
       " 0.1760667361111111,\n",
       " 1.108777372685185,\n",
       " 0.8120342013888888,\n",
       " 1.0077310416666665,\n",
       " 1.594409710648148,\n",
       " 0.10533093750000001,\n",
       " 1.704942303240741,\n",
       " 1.0030325347222222,\n",
       " 666.4737662615742,\n",
       " 0.06776693287037037,\n",
       " 0.19470319444444442,\n",
       " 0.7940530439814816,\n",
       " 685.925716400463,\n",
       " 7.932876689814815,\n",
       " 78.95071554398147,\n",
       " 185.9624796412037,\n",
       " 1.965923449074074,\n",
       " 0.847257199074074,\n",
       " 374.9066226157408,\n",
       " 54.70576020833334,\n",
       " 693.112543935185,\n",
       " 384.45083290509257,\n",
       " 95.6390231712963,\n",
       " 8.317265324074073,\n",
       " 62.700977789351846,\n",
       " 80.76389185185185,\n",
       " 408.9231008217592,\n",
       " 408.54133114583334,\n",
       " 6.967215208333333,\n",
       " 395.6601541203704,\n",
       " 81.70252043981482,\n",
       " 166.70735695601851,\n",
       " 307.72823480324075,\n",
       " 592.5972484953704,\n",
       " 179.5533398148148,\n",
       " 172.83983621527776,\n",
       " 313.7531480902778,\n",
       " 0.05882349537037038,\n",
       " 307.7982844097222,\n",
       " 54.576508333333344,\n",
       " 47.40022631944444,\n",
       " 278.5704750925926,\n",
       " 307.64701196759256,\n",
       " 446.75300498842597,\n",
       " 185.62084354166666,\n",
       " 48.05162416666666,\n",
       " 56.36216226851852,\n",
       " 408.7523235416666,\n",
       " 84.84518410879629,\n",
       " 157.63072302083336,\n",
       " 275.6230993634259,\n",
       " 6.34815269675926,\n",
       " 102.56516887731482,\n",
       " 118.95022881944443,\n",
       " 755.7159003935185,\n",
       " 472.58613736111107,\n",
       " 248.42338988425925,\n",
       " 51.4111482175926,\n",
       " 33.7519650462963,\n",
       " 1.551618333333333,\n",
       " 180.68687538194445,\n",
       " 2.343799108796296,\n",
       " 0.013296006944444445,\n",
       " 24.011005208333334,\n",
       " 244.6118231134259,\n",
       " 171.61602144675928,\n",
       " 250.6624854861111,\n",
       " 151.67588269675926,\n",
       " ...]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp_time_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Montour WMA - Idaho Fish and Game',\n",
       " 'address': 'Montour WMA - Idaho Fish and Game, Montour Rd, Emmett, ID 83617',\n",
       " 'gmap_id': '0x54af0dfadab474e1:0x3ae5c949132941d8',\n",
       " 'description': None,\n",
       " 'latitude': 43.9295808,\n",
       " 'longitude': -116.3333273,\n",
       " 'category': ['Hunting area'],\n",
       " 'avg_rating': 4.4,\n",
       " 'num_of_reviews': 17,\n",
       " 'price': None,\n",
       " 'hours': None,\n",
       " 'MISC': {'Accessibility': ['Wheelchair accessible parking lot']},\n",
       " 'state': None,\n",
       " 'relative_results': ['0x54af0df970009eab:0x998e663a1d2ea45',\n",
       "  '0x54af0e08fb885aed:0xf626feadb2775442',\n",
       "  '0x54afa0ce7af7268b:0x4b98fe1767238dc4',\n",
       "  '0x54afc0324c4ca65b:0x808e759ecacfab1c',\n",
       "  '0x54afb8ee4d09b825:0x50112376cec8c0ff'],\n",
       " 'url': 'https://www.google.com/maps/place//data=!4m2!3m1!1s0x54af0dfadab474e1:0x3ae5c949132941d8?authuser=-1&hl=en&gl=us'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bizs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_id': '108480743392575424354',\n",
       " 'name': 'Dan Shadix',\n",
       " 'time': 1525705287828,\n",
       " 'rating': 5,\n",
       " 'text': 'Love this float on paddle boards.  Nice flat water and fairly slow.',\n",
       " 'pics': None,\n",
       " 'resp': None,\n",
       " 'gmap_id': '0x54af0dfadab474e1:0x3ae5c949132941d8'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_reviews = defaultdict(lambda: None)\n",
    "for r in reviews:\n",
    "    if r['resp'] and 'time' in r['resp']:\n",
    "        business_reviews[r['gmap_id']] = r['resp']['time'] - r['time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31616"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniq_vals, counts = np.unique([r['gmap_id'] for r in reviews], return_counts=True)\n",
    "len(uniq_vals[counts > 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3892636"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8122002673766568"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "31616/3892636*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
